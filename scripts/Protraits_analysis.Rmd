---
title: "Protraits: data analysis"
author: "Joy Vaz"
date: "December 16, 2019"
output: html_document
---

```{r setup, include=FALSE, echo=FALSE}
rm(list = ls())

library("knitr")
opts_chunk$set(tidy=T, warning=F, message=F)
# opts_knit$set(root.dir = "/home/drakelab/Dropbox/joyvaz/PROTraits/") # HMM left
# opts_knit$set(root.dir = "/home/jvaz/Projects/PROTraits/") # HMM right
# opts_knit$set(root.dir = "C:/Rprojects/Protraits_Joy") # My PC
```


```{r brt xgboost, include=FALSE}

library(Matrix)
library(data.table)
library(tidyverse)
library(magrittr)

protraits <- read_csv("data/modified/protraits_20200225") %>% 
  select(-c(protname, zscore, cscore))

# remove highly correlated vars

protraits <- protraits %>% 
  select(-c(numhosts, numgmpdrecords, 
            weighted.betweenness, bet.uni, deg.uni,
            googlehits))

response <- "zoostat"

tmp_prot <- data.table(protraits)


```


```{r corr}

library(GGally)

ggcorr(as.data.frame(tmp_prot_Train) , method = c("everything", "pearson"), palette = "PuOr", label_size = 1)


```

```{r train_test, include=FALSE}

library(caret)
library(xgboost)

# subset data into training vs testing 
set.seed(191212)
trainIndex_prot <- createDataPartition(tmp_prot$zoostat, p = .65, 
                                     list = FALSE, 
                                     times = 1)
tmp_prot_Train <- data.table(tmp_prot[ trainIndex_prot,])
tmp_prot_Test  <- data.table(tmp_prot[-trainIndex_prot,])

# in order for model matrix to work properly, need to set na.action to pass
previous_na_action <- options('na.action')
options(na.action='na.pass')

sparse_matrix_prot <- Matrix::sparse.model.matrix(zoostat ~ ., data = tmp_prot_Train)[,-1] # create a model matrix of the training data predictor variables  

## Cross Validation -----

# 5-fold cross validation to determine best model parameters (chosen by lowering test error)
# set gamma > 0, lowered eta, to help with overfitting

# Grid search ----

# create hyperparameter grid
hyper_grid <- expand.grid(
  eta = c(0.01, 0.05, 0.1, 0.3),   # analogous to learning rate in GBM
  max_depth = c(1, 3, 5),          # maximum depth of a tree, used to control over-fitting
  min_child_weight = c(1, 2, 3),   # minimum sum of weights of all observations required in a child, similar to min_child_leaf in GBM
  gamma = c(0.35, 0.4, 0.5),       # specifies the minimum loss reduction required to make a split
  alpha = c(0.3, 0.4, 0.5),        # L1 regularization term on weight (analogous to Lasso regression)
  subsample = c(0.65, 0.8, 1), 
  colsample_bytree = c(0.7, 0.8, 0.9),
  optimal_trees = 0,               
  max_AUC_train <- 0,
  max_AUC_test <- 0,
  max_AUC_diff <- 0,
  optimal_trees <- 0,
  min_RMSE_train <- 0,
  min_RMSE_test <- 0,
  min_RMSE_diff <- 0,
  min_err_train <- 0,
  min_err_test <- 0,
  min_error_diff <- 0
)

# lambda - L2 regularization term on weights (analogous to Ridge regression)

nrow(hyper_grid)

# grid search 
for(i in 1:nrow(hyper_grid)) {
  
  # create parameter list
  params <- list(
    eta = hyper_grid$eta[i],
    max_depth = hyper_grid$max_depth[i],
    min_child_weight = hyper_grid$min_child_weight[i],
    gamma = hyper_grid$gamma[i],
    alpha = hyper_grid$alpha[i],
    subsample = hyper_grid$subsample[i],
    colsample_bytree = hyper_grid$colsample_bytree[i]
  )
  
  # reproducibility
  set.seed(2145)
  
  # train model
  xgb.tune <- xgb.cv(
    params = params,
    data = sparse_matrix_prot,
    stratified = TRUE,
    label = tmp_prot_Train$zoostat,
    nrounds = 500,
    nfold = 5,
    objective = "binary:logistic", #logistic regression for binary classification, returns predicted probability
    verbose = 0,                   # silent
    early_stopping_rounds = 15,     # stop if no improvement for 15 consecutive trees
    metrics = list("error", "auc", "rmse")
  )
  
  # add min training error and trees to grid
  hyper_grid$max_AUC_train[i] <- max(xgb.tune[["evaluation_log"]][["train_auc_mean"]])
  hyper_grid$max_AUC_test[i] <- max(xgb.tune[["evaluation_log"]][["test_auc_mean"]])
  hyper_grid$max_AUC_diff[i] <- hyper_grid$max_AUC_train[i] - hyper_grid$max_AUC_test[i]
  hyper_grid$optimal_trees[i] <- which.min(xgb.tune[["evaluation_log"]][["test_rmse_mean"]])
  hyper_grid$min_RMSE_train[i] <- min(xgb.tune[["evaluation_log"]][["train_rmse_mean"]])
  hyper_grid$min_RMSE_test[i] <- min(xgb.tune[["evaluation_log"]][["test_rmse_mean"]])
  hyper_grid$min_RMSE_diff[i] <- hyper_grid$min_RMSE_test[i] - hyper_grid$min_RMSE_train[i]
  hyper_grid$min_err_train[i] <- max(xgb.tune[["evaluation_log"]][["train_error_mean"]])
  hyper_grid$min_err_test[i] <- max(xgb.tune[["evaluation_log"]][["test_error_mean"]])
  hyper_grid$min_error_diff[i] <- hyper_grid$min_error_test[i] - hyper_grid$min_error_train[i]
}

#change na.action back to default
options(na.action=previous_na_action$na.action)

#change na.action back to default
options(na.action=previous_na_action$na.action)

```

```{r grid search results}


hyper_grid %>% as.tbl() %>%
  dplyr::arrange(max_AUC_test) %>%
  tail(10)

hyper_grid %>% as.tbl() %>% 
  dplyr::arrange(min_RMSE_test) %>%
  head(10)

hyper_grid %>% as.tbl() %>% 
  dplyr::arrange(min_RMSE_test) %>%
  head(10)


```

```{r train_test, include=FALSE}

xgb.tune.p1 <- xgb.cv(
    eta = 0.,
    max_depth = ,
    min_child_weight = ,
    gamma = ,
    alpha = ,
    subsample = ,
    colsample_bytree = ,
    data = sparse_matrix_prot,
    stratified = TRUE,
    label = tmp_prot_Train$zoostat,
    nrounds = 1000,
    nfold = 5,
    objective = "binary:logistic", #logistic regression for binary classification, returns predicted probability
    verbose = 0,                   # silent
    early_stopping_rounds = 15,    # stop if no improvement for 15 consecutive trees
    metrics = list("error", "auc", "rmse")
  )
```

```{r plots, echo=FALSE}

# PLOT --------

for (j in 1:length(cv_seeds)) {
  cv_log_auc_p1$round <- rownames(cv_log_auc_p1)
  ggplot(cv_log_auc_p1, aes(x=round)) + 
  geom_line(aes(y = cv_log_auc_p1[j]))
  
}

library(ggplot2)

cv_log_auc_p3$round <- as.numeric(rownames(cv_log_auc_p1))

p <- ggplot(cv_log_auc_p3, aes(x = round)) + 
  geom_line(aes(y = `2420`)) + 
  geom_line(aes(y = `706`)) + 
  geom_line(aes(y = `626`)) + 
  geom_line(aes(y = `80085`)) + 
  geom_line(aes(y = `303`)) + 
  geom_line(aes(y = `903`)) + 
  geom_line(aes(y = `4096`)) + 
  geom_line(aes(y = `779`)) + 
  geom_line(aes(y = `73`)) + 
  geom_line(aes(y = `1312`)) + 
  geom_line(aes(y = `1230`)) + 
  geom_line(aes(y = `656`)) + 
  geom_line(aes(y = `1984`)) + 
  geom_line(aes(y = `1994`)) + 
  geom_line(aes(y = `1024`)) + 
  geom_line(aes(y = `2048`)) + 
  geom_line(aes(y = `1948`)) + 
  geom_line(aes(y = `616`)) + 
  geom_line(aes(y = `12`)) + 
  geom_line(aes(y = `89`)) + 
  geom_line(aes(y = `102`)) + 
  geom_line(aes(y = `215`)) + 
  geom_line(aes(y = `1495`)) + 
  geom_line(aes(y = `777`)) + 
  geom_line(aes(y = `9988`)) + 
  geom_line(aes(y = `5`)) + 
  geom_line(aes(y = `538`)) + 
  geom_line(aes(y = `202`)) + 
  geom_line(aes(y = `396`)) + 
  geom_line(aes(y = `1419`))
p

#------------

set.seed(2145)
cv_bst_prot <- xgb.cv(params = params1,
                    data = sparse_matrix_prot,
                    stratified = TRUE,
                    label =  tmp_prot_Train$zoostat,
                    nfold = 5, 
                    nrounds = 60, 
                    metrics = list("error", "auc"))

max(cv_bst_prot[["evaluation_log"]][["test_auc_mean"]])



print(cv_bst_prot, verbose = T)


bst_prot <- xgboost(sparse_matrix_prot, 
                  label = tmp_prot_Train$zoostat,
                  params = list(max.depth = 5, eta = 0.1, 
                                nthread = 2, gamma = 0.35, alpha = 0.3,
                                objective = "binary:logistic", 
                                eval_metric = list( "auc")),
                  nrounds = 55)

# bst_prot$evaluation_log

#change na.action back to default
options(na.action=previous_na_action$na.action)

#change na.action back to default
options(na.action=previous_na_action$na.action)


```


Variable importance plots for the model, along with partial dependence plots for the top variables.
```{r vip, echo=F, comment=F, warning = F}
#

library(pdp)
library(Ckmeans.1d.dp)

importance_prot <- xgb.importance(feature_names = colnames(sparse_matrix_prot), model = bst_prot)


xgb.plot.importance(importance_prot, rel_to_first = TRUE, xlab = "Relative importance")

gg_prot <- xgb.ggplot.importance(importance_prot, measure = "Gain", rel_to_first = TRUE)
gg_prot

# # predict values in test set (Wait to do this until model is finalized!)
# sparse_matrix_prot_Test <- sparse.model.matrix(zoostat ~ ., data = tmp_prot_Test)[,-1] # create a model matrix of the test dataset
# 
# y_pred_prot <- predict(bst_prot, sparse_matrix_prot_Test) # gives error because testing data has less features than train data. Factor features in test set have less levels than those in training set, so feature names in sparse_matrix_prot@Dimnames[[2]] and sparse_matrix_prot_Test@Dimnames[[2]] are different. Need to add these features in test set and have them all be 0.
# y_pred_prot <- ifelse (y_pred_prot > 0.5,1,0)
# 
# #how many are incorrectly classified?
# test_error_prot <- 1 - sum(y_pred_post ==  tmp_prot_Test$zoostat)/length(y_pred_prot)
# print(test_error_prot)
# 

```

```{r pdps, echo=F, warning=F, message=F}
## partial dependence plots

important_vars <- importance_prot$Feature

v <- importance_prot$Feature
length(v)

# c-ICE curves and PDPs


p1 <- pdp::partial(bst_prot, pred.var = as.character(important_vars[1]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2", 
              train = sparse_matrix_prot, type = "classification", prob = T)
p2 <- pdp::partial(bst_prot, pred.var = as.character(important_vars[2]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2",
              train = sparse_matrix_prot, type = "classification", prob = T)

p3 <- pdp::partial(bst_prot, pred.var = as.character(important_vars[3]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2", 
              train = sparse_matrix_prot, type = "classification", prob = T)
p4 <- pdp::partial(bst_prot, pred.var = as.character(important_vars[4]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2",
              train = sparse_matrix_prot, type = "classification", prob = T)
p5 <- pdp::partial(bst_prot, pred.var = as.character(important_vars[5]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2",
              train = sparse_matrix_prot, type = "classification", prob = T)

p6 <- pdp::partial(bst_prot, pred.var = as.character(important_vars[6]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2", 
              train = sparse_matrix_prot, type = "classification", prob = T)
p7 <- pdp::partial(bst_prot, pred.var = as.character(important_vars[7]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2", 
              train = sparse_matrix_prot, type = "classification", prob = T)



# Figure 2
grid.arrange(p1, p2, ncol = 2)
grid.arrange(p3, p4, p5, ncol = 3)
grid.arrange(p6, p7, ncol = 2)

grid.arrange(p1, p2, p3, ncol = 3)


```
