---
title: "Protraits: Results"
author: "Joy Vaz"
date: "March 09, 2021"
output: html_document
---



```{r setup, include=FALSE, echo=FALSE}
library("knitr")
opts_chunk$set(tidy=T, warning=F, message=F, include = T)
opts_knit$set(root.dir = "C:/Rprojects/Protraits_Joy/")
```

```{r load_packages, include=F, message=F, warning=F}

library(xgboost)
library(Matrix)
library(data.table)
library(tidyverse)
library(caret)
library(magrittr)
library(corrplot)
library(mlbench)
library(tictoc)
library(BRRR)
library(pdp)
library(Ckmeans.1d.dp)
library(readxl)

```

## Data summary

The response variable is whether a protozoa species is zoonotic or not, n = 228.

With an 65/35 split for training and testing data, $n_{train} = 149$, and $n_{test} = 79$. The data is split so that the proportion of positive and negative observations is equal between training and testing sets. 


```{r load_data}

rm(list = ls())

protnames <- read.csv("./data/modified/protnames.csv", row.names = 1)

#create a list of the files from your target directory

file_list_full <- list.files(path="./data/modified/protraits", full.names = T)
file_list <- list.files(path="./data/modified/protraits")
df_names <- gsub(".csv", "", file_list)

#initiate a blank data frame, each iteration of the loop will append the data from the given file to this variable
protraits <- data.frame(protnames)

#had to specify columns to get rid of the total column
for (i in 1:length(file_list)){
  x <- read.csv(file_list_full[i])[-1] #each file will be read in, specify which columns
  assign(df_names[i], x)
  protraits <- left_join(protraits, x, by = "protname")
}

# names(protraits)

# write.csv(protraits, "./data/modified/protraits_full")

```

```{r feature_selection}

# Create correlation matrix

data <- select_if(protraits, is.numeric)
correlationMatrix <- cor(data, use = "pairwise.complete.obs")
correlation.df <- correlationMatrix %>% as.data.frame() %>% mutate(rowID = rownames(correlationMatrix))

corrPairs <- melt(correlation.df) %>% rename(feature1 = rowID, feature2 = variable, PCC = value)
corrPairs <- corrPairs[!duplicated(data.frame(t(apply(corrPairs[, 1:2],1,sort)))),]

# Plot

# corrplot(correlationMatrix, method="color", tl.col = "black", tl.cex = 0.6, number.cex = 0.5, 
#          na.label = "NA", na.label.col = "darkgray", addCoef.col = "darkgray", number.digits = 1)

highlyCorrelated <- filter(corrPairs, PCC > 0.7 | PCC < (-0.7))

# Remove highly correlated or redundant vars
protraits_trimmed <- protraits %>% select(-c(prot_degree, 
                                             prot_normalised.degree,
                                             prot_betweenness,
                                             prot_closeness,
                                             mean_host_degree,
                                             mean_host_normalised.degree,
                                             mean_host_betweenness,
                                             mean_host_closeness,
                                             starts_with("med_host_bipartite_"),
                                             med_host_degree,
                                             med_host_close,
                                             med_host_between,
                                             med_host_eigen,
                                             med_host_AdultBodyMass_wEXT,
                                             med_host_NeonateBodyMass_wEXT,
                                             med_host_LittersPerYear_wEXT,
                                             med_host_SexualMaturityAge,
                                             med_host_Terrestrial,
                                             med_host_Aerial,
                                             med_host_Marine,
                                             med_host_Freshwater,
                                             n_realms,
                                             n_biomes,
                                             muscular,
                                             skeletal,
                                             circulatory,
                                             respiratory,
                                             digestive,
                                             immune,
                                             urinary,
                                             nervous,
                                             endocrine,
                                             reproductive,
                                             lymphatic,
                                             integumentary,
                                             ocular,
                                             multi,
                                             mean_.GDP_2015),
                                          mean_HDI = mean_.HDI_2015)

# Update corr matrix

data <- select_if(protraits_trimmed, is.numeric)
correlationMatrix <- cor(data, use = "pairwise.complete.obs")
correlation.df <- correlationMatrix %>% as.data.frame() %>% mutate(rowID = rownames(correlationMatrix))

corrPairs <- melt(correlation.df) %>% rename(feature1 = rowID, feature2 = variable, PCC = value)
corrPairs <- corrPairs[!duplicated(data.frame(t(apply(corrPairs[, 1:2],1,sort)))),]

highlyCorrelated_trimmed <- filter(corrPairs, PCC > 0.7 | PCC < (-0.7))

#Plot

corrplot(correlationMatrix, method="color", tl.col = "black", tl.cex = 0.75, number.cex = 0.4, 
         na.label = "NA", na.label.col = "darkgray", addCoef.col = "darkgray", number.digits = 1)

# Calculate coverage

feature_names <- names(protraits_trimmed)
completeness <- protraits_trimmed %>% summarise_all(function(x) mean(!is.na(x))) %>% as.numeric()
datacompleteness <- cbind(names(protraits_trimmed), completeness) %>% as.data.frame()
protraits_trimmed %>% summarise_all(function(x) mean(!is.na(x))) %>% as.numeric() %>% plot(type = 'h')

# I'm keeping max phylogenetic distance even though it's got such low coverage because I'm curious

```



```{r grouping variables, include=F}
# predictors, grouped by cateogory (A, B, C, D)

A_preds <- c("tm_close", "tm_nonclose")

B_preds <- c("tm_vector", "tm_intermediate")

C_preds <- c()

D_preds <- c()

response <- "zoostat"

# tmp_prot <- data.table(protraits[, c(A_preds, B_preds, C_preds, D_preds, response)])


```



Prepare model matrix

```{r train_test}


tmp_protraits <- protraits_trimmed %>% as_tibble() %>% select(-protname)
tmp_protraits2 <- protraits %>% as_tibble() %>% select(-protname)
tmp_prot <- data.table(tmp_protraits2)

# subset data into training vs testing 
set.seed(191212)
trainIndex_prot <- createDataPartition(tmp_prot$zoostat, p = .65, 
                                     list = FALSE, 
                                     times = 1)
tmp_prot_Train <- data.table(tmp_prot[ trainIndex_prot,])
tmp_prot_Test  <- data.table(tmp_prot[-trainIndex_prot,])

# Actual zoostat
real.class <- tmp_prot_Train$zoostat %>% as.factor()
table(real.class) # the training set has 149 out of 228 rows in the full dataset. 10/149 are zoonotic and 139/149 are non-zoonotic.

# in order for model matrix to work properly, need to set na.action to pass
previous_na_action <- options('na.action')
options(na.action='na.pass')

sparse_matrix_prot <- Matrix::sparse.model.matrix(zoostat ~ ., data = tmp_prot_Train)[,-1] # create a model matrix of the training data predictor variables  

dtrain <- xgb.DMatrix(data = sparse_matrix_prot, label = tmp_prot_Train$zoostat)

```


After partitioning the data into training and testing sets, I ran 5 fold cross-validation using a tuning function to determine the best parameters for the model

To reduce overfitting, I reduced the eta (learning rate), and increased gamma and alpha (regularization parameters).

eta [default=0.3]
- Step size shrinkage used to shrink the feature weights after each boosting step. Make the boosting process more conservative to prevent overfitting.
- Analogous to learning rate in GBM
- Typical final values to be used: 0.01-0.2
- The tuning function below cycles through the following values: 0.01, 0.02, 0.03, 0.04, 0.05

gamma [default=0] 
- Minimum loss reduction required to make a further partition on a leaf node of the tree (a node is split only when the resulting split gives a positive reduction in the loss function). 
- The larger gamma is, the more conservative the algorithm will be. 
- The tuning function below cycles through the following values: 0.10, 0.15, 0.20, 0.25, 0.30, 0.35

alpha [default=0] 
- L1 regularization term on weights (analogous to Lasso regression). 
- Increasing this value will make model more conservative. 
- Can be used in case of very high dimensionality so that the algorithm runs faster.
- The tuning function below cycles through the following values: 0.35, 0.40, 0.45, 0.50, 0.55


```{r tune parameters}

# source tune.BRT function
source("./scripts/tuneBRT_function.R")

# Use tune.BRT to determine best combination of eta, gamma, and alpha.

tic()
# param_log <- tune.brt(dtrain = dtrain, n.rounds = 512, n.thread = 4) 
toc()
skrrrahh("soulja")

# print(param_log) 

# returns a df of parameter combinations and the mean test logloss, mean test error, and TSS

```

After inspecting the evaluation log, the best parameter combination is eta = 0.01, gamma = 0.35, and alpha = 0.5.
The gives the highest TSS (0.17122302), lowest error (0.0819228), and 2nd lowest logloss (0.3215248)


Perform 5-fold crossvalidation using these parameters
```{r}

# reproducibility
set.seed(1024) # this is the same seed as what is in the tune.BRT function

# 5-fold cross validated XGBoost model with 1024 trees and tuned parameters
cv_bst_prot <- xgb.cv(params = list(max.depth = 3, nthread = 4, 
                                    eta = 0.01,
                                    gamma = 0.35, 
                                    alpha = 0.5,
                                    objective = "binary:logistic"),
                      data = dtrain,
                      stratified = TRUE,
                      verbose = F,
                      nfold = 5, 
                      nrounds = 1024,
                      metrics = list("logloss", "error"),
                      scale_pos_weight = 15,
                      prediction = T
                      )
# Prediction probabilities
pred <- cv_bst_prot$pred
# Set cutoff threshold
pred.class <- ifelse(pred >= 0.5, 1, 0) %>% as.factor()

# Create the confusion matrix
confusionMatrix(pred.class, real.class, positive="1")

```

Plot logloss curve showing how mean train and test logloss varies with the number of trees

```{r}
# plot of logloss vs number of trees
ggplot(cv_bst_prot$evaluation_log) +
  geom_line(aes(iter, train_logloss_mean, color = "turquoise")) +
  geom_line(aes(iter, test_logloss_mean, color = "orange")) +
  scale_color_discrete(name = "Key", labels = c("Test logloss mean", "Train logloss mean")) +
  ylab("logloss (mean)") + xlab("number of trees")

cv_bst_prot[["evaluation_log"]] %>% tail()
```

Replot curve with a smaller number of trees (350)

```{r}
# replot upto 350 trees
ggplot(cv_bst_prot$evaluation_log[1:512]) +
  geom_line(aes(iter, train_logloss_mean, color = "turquoise")) +
  geom_line(aes(iter, test_logloss_mean, color = "orange")) +
  scale_color_discrete(name = "Key", labels = c("Test logloss mean", "Train logloss mean")) +
  ylab("logloss (mean)") + xlab("number of trees")

```


```{r}
# get max number of trees that minimize train and test logloss
cv_bst_prot$evaluation_log %>%
  dplyr::summarise(
    ntrees.train = max(which(train_logloss_mean == min(train_logloss_mean))),
    logloss.train   = min(train_logloss_mean),
    ntrees.test  = max(which(test_logloss_mean == min(test_logloss_mean))),
    logloss.test   = min(test_logloss_mean)
  )

```

Plot deviance curve showing how mean train and test errors vary with the number of trees

```{r}

# Plot error vs number of trees
ggplot(cv_bst_prot$evaluation_log) +
  geom_line(aes(iter, train_error_mean, color = "turquoise")) +
  geom_line(aes(iter, test_error_mean, color = "orange")) +
  scale_color_discrete(name = "Key", labels = c("Test error mean", "Train error mean")) +
  ylab("Error (mean)") + xlab("number of trees")

cv_bst_prot[["evaluation_log"]] %>% tail()

# Replot with 640 trees
ggplot(cv_bst_prot$evaluation_log[1:640]) +
  geom_line(aes(iter, train_error_mean, color = "turquoise")) +
  geom_line(aes(iter, test_error_mean, color = "orange")) +
  scale_color_discrete(name = "Key", labels = c("Test error mean", "Train error mean")) +
  ylab("Error (mean)") + xlab("number of trees")


```


```{r}
# get max number of trees that minimize train and test error
cv_bst_prot$evaluation_log %>%
  dplyr::summarise(
    ntrees.train = max(which(train_error_mean == min(train_error_mean))),
    error.train   = min(train_error_mean),
    ntrees.test  = max(which(test_error_mean == min(test_error_mean))),
    error.test   = min(test_error_mean)
  )

```


Still not sure what is the best number of trees.


```{r}


BRT_prot <- xgboost(dtrain,
                    params = list(max.depth = 3, eta = 0.01, 
                                  nthread = 4, gamma = 0.35, alpha = 0.5,
                                  objective = "binary:logistic",
                                  eval_metric = "logloss",
                                  eval_metric = "error"),
                    verbose = F,
                    nrounds = 1024)

BRT_prot[["evaluation_log"]]

ggplot(BRT_prot$evaluation_log) +
  geom_line(aes(iter, train_logloss)) +
  ylab("logloss") + xlab("iter")

ggplot(BRT_prot$evaluation_log) +
  geom_line(aes(iter, train_error)) +
  ylab("logloss") + xlab("iter")


#change na.action back to default
options(na.action=previous_na_action$na.action)
```

```{r vip, echo=F, comment=F, warning = F}



importance_prot <- xgb.importance(feature_names = colnames(sparse_matrix_prot), model = BRT_prot)

xgb.plot.importance(importance_prot, rel_to_first = TRUE, xlab = "Relative importance")

gg_prot <- xgb.ggplot.importance(importance_prot, measure = "Gain", rel_to_first = TRUE)
gg_prot

```

```{r pdps, echo=F, warning=F, message=F}
## partial dependence plots

important_vars <- importance_prot$Feature

v <- importance_prot$Feature
length(v)

# c-ICE curves and PDPs

p1 <- pdp::partial(BRT_prot, pred.var = as.character(important_vars[1]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2", 
              train = sparse_matrix_prot, type = "classification", prob = T)
p2 <- pdp::partial(BRT_prot, pred.var = as.character(important_vars[2]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2",
              train = sparse_matrix_prot, type = "classification", prob = T)

p3 <- pdp::partial(BRT_prot, pred.var = as.character(important_vars[3]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2", 
              train = sparse_matrix_prot, type = "classification", prob = T)
p4 <- pdp::partial(BRT_prot, pred.var = as.character(important_vars[4]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2",
              train = sparse_matrix_prot, type = "classification", prob = T)
p5 <- pdp::partial(BRT_prot, pred.var = as.character(important_vars[5]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2",
              train = sparse_matrix_prot, type = "classification", prob = T)

p6 <- pdp::partial(BRT_prot, pred.var = as.character(important_vars[6]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2", 
              train = sparse_matrix_prot, type = "classification", prob = T)



grid.arrange(p1, p2, ncol = 2)
grid.arrange(p3, p4, ncol = 2)
grid.arrange(p5, p6, ncol = 2)

```


```{r permuting by group, eval = F, include=F}
# For the code for my permutations see below (not run here due to compuation time)

# now try permuting variables by group; but independently of one another to break any correlation

iter <- 3
auc_A <- NULL
auc_B <- NULL
auc_C <- NULL
auc_D <- NULL

auc_df <- data.frame(NULL)
for(i in 1:iter){
  
  for(j in 1:length(A_preds)){
    for(k in 1:2){
      # create a model matrix of A predictor variables
      perm_tmp_prot_Train <- tmp_prot_Train[, c(1:2, 9)]
      perm_tmp_prot_Train[,j] <-tmp_prot_Train[sample(1:nrow(tmp_prot_Train)), ..k]
      perm_sparse_matrix_prot <- sparse.model.matrix(zoostat ~ ., data = perm_tmp_prot_Train)[,-1]  
      dtrain <- xgb.DMatrix(data = sparse_matrix_prot, label = tmp_prot_Train$zoostat)
    
      perm_bst_prot <- xgboost(dtrain,
                               params = list(max.depth = 3, eta = 0.025, 
                                    nthread = 4, gamma = 0.15, alpha = 0.4,
                                    objective = "binary:logistic",
                                    eval_metric = list("auc")),
                               nrounds = 4)
      auc_A[i] <- perm_bst_prot$evaluation_log[4]$train_auc
    }
    
  }
    
  for(j in 1:length(B_preds)){
    # create a model matrix of B predictor variables
    perm_tmp_prot_Train <- tmp_prot_Train[, c(3:4, 9)]
    for(k in 3:4){
      perm_tmp_prot_Train[,j] <-tmp_prot_Train[sample(1:nrow(tmp_prot_Train)), ..k]
      perm_sparse_matrix_prot <- sparse.model.matrix(zoostat ~ ., data = perm_tmp_prot_Train)[,-1]  
      dtrain <- xgb.DMatrix(data = sparse_matrix_prot, label = tmp_prot_Train$zoostat)
    
      perm_bst_prot <- xgboost(dtrain,
                               params = list(max.depth = 3, eta = 0.025, 
                                    nthread = 4, gamma = 0.15, alpha = 0.4,
                                    objective = "binary:logistic",
                                    eval_metric = list("auc")),
                               nrounds = 4)
      auc_B[i] <- perm_bst_prot$evaluation_log[4]$train_auc
    }
   

  }
  auc_df <- data.frame(auc_A, auc_B)
   
}

```

