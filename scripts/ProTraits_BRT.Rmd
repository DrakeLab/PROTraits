---
title: "Protraits: Results"
author: "Joy Vaz"
date: "March 30, 2021"
output: html_document:
#   toc: TRUE # table of contents
---



```{r setup, include=FALSE, echo=FALSE}
library("knitr")
opts_chunk$set(tidy=T, warning=F, message=F, include = T)
opts_knit$set(root.dir = "C:/Rprojects/Protraits_Joy/")
```

```{r load_packages, echo=F, message=F, warning=F}

library(xgboost)
library(Matrix)
library(data.table)
library(tidyverse)
library(caret)
library(magrittr)
library(corrplot)
library(mlbench)
library(tictoc)
library(BRRR)
library(pdp)
library(Ckmeans.1d.dp)
library(readxl)
library(pROC)

```

# Data summary

Traitsof 228 protozoa species are recorded in the dataset. See [this data table](https://outlookuga-my.sharepoint.com/:x:/g/personal/jjc99699_uga_edu/EQB4ODI2o45DpMgeI2sCQ9oBAoX_ThrV9VhL-R2rfjfDrg?e=oTh6NR) for variable definistions and coverage. 

The binary response variable indicates whether a protozoa species is zoonotic or not.

```{r load_data, include=FALSE, eval = F}

rm(list = ls())

protnames <- read.csv("./data/modified/protnames.csv", row.names = 1)

#create a list of the files from your target directory

file_list_full <- list.files(path="./data/modified/protraits", full.names = T)
file_list <- list.files(path="./data/modified/protraits")
df_names <- gsub(".csv", "", file_list)

#initiate a blank data frame, each iteration of the loop will append the data from the given file to this variable
protraits <- data.frame(protnames)

for (i in 1:length(file_list)){
  x <- read.csv(file_list_full[i], row.names = 1)
  assign(df_names[i], x)
  protraits <- left_join(protraits, x, by = "parname")
}

head(protraits)
names(protraits)

protraits <- protraits %>% rename(ParasiteBinomialName = parname, CommunitySize = parcommsize,
                                  PropCommunityZoonotic = propparcommzoon,
                                  PropHostsZoonoticCarriers = prophostzoon, 
                                  EcoRealm = main_realm, NumEcoregions = n_ecoregions, 
                                  MeanGDP = meanGDP_per_cap, ZoonoticStatus = zoostat, 
                                  WebOfScienceHits = WoSHits, REMOVE = partype,
                                  Phylum = parphylum, Class = parclass, 
                                  Order = parorder, Family = parfamily,
                                  CloseContactTransmission = close, NonCloseContactTransmission = nonclose,
                                  VectorTransmission = vector, IntermediateTransmission = intermediate) %>% 
  mutate(NumTransmissionModes = CloseContactTransmission + NonCloseContactTransmission +
                                    VectorTransmission + IntermediateTransmission) %>% 
  select(-REMOVE)

names(protraits)

```

```{r feature_selection, include=F, eval = F}

# Create correlation matrix

data <- select_if(protraits, is.numeric)

correlationMatrix <- cor(data, use = "pairwise.complete.obs")
correlation.df <- correlationMatrix %>% as.data.frame() %>% mutate(rowID = rownames(correlationMatrix))

corrPairs <- melt(correlation.df) %>% rename(feature1 = rowID, feature2 = variable, PCC = value)
corrPairs <- corrPairs[!duplicated(data.frame(t(apply(corrPairs[, 1:2],1,sort)))),]

highlyCorrelated <- filter(corrPairs, PCC > 0.7 | PCC < (-0.7))

#Plot

corrplot(correlationMatrix, method="color", tl.col = "black", tl.cex = 0.5, number.cex = 0.5, 
         na.label = "NA", na.label.col = "darkgray", addCoef.col = "darkgray", number.digits = 2)

rowMeans(correlation.df[1:34]) %>% cbind(names(correlation.df)[1:34]) %>% view()
# remove CommunitySize

protraits_tmp <- protraits %>% select(-CommunitySize)
data <- select_if(protraits_tmp, is.numeric)
correlationMatrix <- cor(data, use = "pairwise.complete.obs")
correlation.df <- correlationMatrix %>% as.data.frame() %>% mutate(rowID = rownames(correlationMatrix))
corrPairs <- melt(correlation.df) %>% rename(feature1 = rowID, feature2 = variable, PCC = value)
corrPairs <- corrPairs[!duplicated(data.frame(t(apply(corrPairs[, 1:2],1,sort)))),]
highlyCorrelated <- filter(corrPairs, PCC > 0.6 | PCC < (-0.6)) 
corrplot(correlationMatrix, method="color", tl.col = "black", tl.cex = 0.75, number.cex = 0.75, 
         na.label = "NA", na.label.col = "darkgray", addCoef.col = "darkgray", number.digits = 2)
# remove NonCloseContactTransmission, MeanGDP, HostPropParZoonootic, ProportionalGenerality, IntermediateTransmission, SexualReproduction

protraits_tmp2 <- protraits_tmp %>% select(-c(NonCloseContactTransmission, MeanGDP, 
                                              HostPropParZoonootic, ProportionalGenerality,
                                              IntermediateTransmission, SexualReproduction))
data <- select_if(protraits_tmp2, is.numeric)
correlationMatrix <- cor(data, use = "pairwise.complete.obs")
correlation.df <- correlationMatrix %>% as.data.frame() %>% mutate(rowID = rownames(correlationMatrix))
corrPairs <- melt(correlation.df) %>% rename(feature1 = rowID, feature2 = variable, PCC = value)
corrPairs <- corrPairs[!duplicated(data.frame(t(apply(corrPairs[, 1:2],1,sort)))),]
highlyCorrelated <- filter(corrPairs, PCC > 0.6 | PCC < (-0.6)) # YAY!
corrplot(correlationMatrix, method="color", tl.col = "black", tl.cex = 0.75, number.cex = 0.75, 
         na.label = "NA", na.label.col = "darkgray", addCoef.col = "darkgray", number.digits = 2)

# write.csv(protraits_tmp2, "./data/modified/protraits_final_final.csv")


```



```{r load_final_dataset}
protraits_final <- read.csv("./data/modified/protraits_final_final.csv", row.names = 1)

head(protraits_final)
names(protraits_final)
# names(protraits_final) %>% sort()

```

### Variable groups

In order to investigate the relative importance of different groups of variables in predicting zoonotic potential, I grouped the variables (n = 33) into six sets: parasite specialism-generalism, community variables, intrinsic traits, host traits, regional/environmental triats, and sampling effort.

```{r group_variables}
# predictors, grouped by category

generalism <- c("NumTransmissionModes",
              "HostDietBreadth",
              "HostHabitatBreadth",
              "HostGeographicRange",
              "HostIslandEndemicity",
              "NumOrganSystems",
              "HostEvolutionaryDistinctiveness",
              "ParasiteBetweenness", 
              "HostBetweenness",
              "NumEcoregions")
community <- c("PropCommunityZoonotic",
               "PropHostsZoonoticCarriers",
               "ParasiteCloseness",
               "HasDomesticHost",
               "HostProportionalGenerality")
intrinsic <- c("Class",
               "Family",
               "Intracellular", 
               "CloseContactTransmission", 
               "VectorTransmission")
hosts <- c("HostInterbirthInterval",
           "HostTrophicLevel",
           "HostPopDensity",
           "HostDietInvertebrate") # remove?
regional <- c("EcoRealm", #main biome (numeric) replaced with factor realm
              "MeanHumanPopDensity",
              "MeanTemp", 
              "MeanPrecipitation") 
sampling <- c("WebOfScienceHits")
response <- "ZoonoticStatus"

```


### Prepare model matrix

The data is split so that the proportion of positive and negative observations is equal between training and testing sets, with an 65/35 split for training and testing data ($n_{train} = 149$, and $n_{test} = 79$). 

```{r train_test}


tmp_protraits <- protraits_final %>% as_tibble() %>% select(-ParasiteBinomialName)
tmp_prot <- data.table(tmp_protraits[, c(generalism, community, intrinsic, hosts, regional, sampling, response)])

# # Calculate coverage
# 
# feature_names <- names(tmp_prot)
# 
# completeness <- tmp_prot %>% summarise_all(function(x) mean(!is.na(x))) %>% as.numeric()
# completeness.pos <- tmp_prot %>% filter(ZoonoticStatus == 1) %>% 
#   summarise_all(function(x) mean(!is.na(x))) %>% as.numeric()
# datacompleteness <- cbind(names(tmp_prot), completeness, completeness.pos) %>% as.data.frame()

# tmp_prot %>% summarise_all(function(x) mean(!is.na(x))) %>% as.numeric() %>% plot(type = 'h')


# subset data into training vs testing 

tmp_prot$ZoonoticStatus <- as.factor(tmp_prot$ZoonoticStatus)

set.seed(1024)
trainIndex_prot <- createDataPartition(tmp_prot$ZoonoticStatus, p = .65, 
                                     list = FALSE, 
                                     times = 1)
# testIndex_prot <- setdiff(c(1:nrow(tmp_prot)), trainIndex_prot)

tmp_prot$ZoonoticStatus <- as.numeric(tmp_prot$ZoonoticStatus)-1 # turn back to 1s ans 0s

tmp_prot_Train <- data.table(tmp_prot[trainIndex_prot,])
# tmp_prot_Test  <- data.table(tmp_prot[-trainIndex_prot,])

# Actual zoostat
real.class <- tmp_prot_Train$ZoonoticStatus %>% as.factor()
table(real.class) # the training set has 147 out of 226 rows in the full dataset. 13/147 are zoonotic
tmp_prot_Test$ZoonoticStatus %>% as.factor() %>% table() # the test set has 79 out of 226 rows in the full dataset. 7/79 are zoonotic

# in order for model matrix to work properly, need to set na.action to pass
previous_na_action <- options('na.action')
options(na.action='na.pass')

# create a model matrix of the training data predictor variables 
sparse_matrix_prot <- Matrix::sparse.model.matrix(ZoonoticStatus ~ ., data = tmp_prot_Train)[,-1]

dtrain <- xgb.DMatrix(data = sparse_matrix_prot, label = tmp_prot_Train$ZoonoticStatus)

```

# Model tuning

After partitioning the data into training and testing sets, I ran 5 fold cross-validation using a custom tuning function to determine the best parameters for the model. In order to reduce overfitting, I selected parameters based on the average test-error, true skill statistic (TSS), and average test-logloss. I reduced the eta (learning rate) to 0.02, and increased alpha and gamma (regularization parameters) to 0.4 and 0.25, respectively, to reduce overfitting. 

### Parameter definitions:

eta [default=0.3]
- Step size shrinkage used to shrink the feature weights after each boosting step. Make the boosting process more conservative to prevent overfitting.
- Analogous to learning rate in GBM
- Typical final values to be used: 0.01-0.2

gamma [default=0] 
- Minimum loss reduction required to make a further partition on a leaf node of the tree (a node is split only when the resulting split gives a positive reduction in the loss function). 
- The larger gamma is, the more conservative the algorithm will be. 

alpha [default=0] 
- L1 regularization term on weights (analogous to Lasso regression). 
- Increasing this value will make model more conservative. 
- Can be used in case of very high dimensionality so that the algorithm runs faster.


```{r tune parameters, eval = F}

# source tune.BRT function
source("./scripts/tuneBRT_function.R")

# Use tune.BRT to determine best combination of eta, gamma, and alpha.

tic()
param_log <- tune.brt(dtrain = dtrain, n.rounds = 512, n.thread = 4) 
toc()
skrrrahh("soulja")

#print(param_log) 

# returns a df of parameter combinations and the mean test logloss, mean test error, and TSS

```
0.02, 0.4, 0.45 (compromise between AUC and F1)

### Cross-validation

```{r cv}

# reproducibility
set.seed(2048)

# 5-fold cross validated XGBoost model with 512 trees and tuned parameters
cv_bst_prot <- xgb.cv(params = list(max.depth = 3, nthread = 4, 
                                    eta = 0.02,
                                    gamma = 0.4, 
                                    alpha = 0.45,
                                    objective = "binary:logistic"),
                      data = dtrain,
                      stratified = TRUE,
                      verbose = F,
                      nfold = 5, 
                      nrounds = 512,
                      metrics = list("logloss", "error", "auc"),
                      scale_pos_weight = 15,
                      prediction = T
                      )

# # this one gave the awesome ranked predictions (it was when the g-measure was messed up, had + instead of * # in the tuning function. fixed that, now parameters changed see above)
# cv_bst_prot <- xgb.cv(params = list(max.depth = 3, nthread = 4, 
#                                     eta = 0.03,
#                                     gamma = 0.325, 
#                                     alpha = 0.55,
#                                     objective = "binary:logistic"),
#                       data = dtrain,
#                       stratified = TRUE,
#                       verbose = F,
#                       nfold = 5, 
#                       nrounds = 512,
#                       metrics = list("logloss", "error", "auc"),
#                       scale_pos_weight = 15,
#                       prediction = T
#                       )
# 
# cv_bst_prot[["evaluation_log"]] %>% view() #best test AUC mean at 56 iter

```

### Choosing a threshold to convert probabilities to binary predictions

```{r binary_classification}

# Prediction probabilities
pred <- cv_bst_prot$pred

pred.df <- data.frame(true.zoostat = tmp_prot_Train$ZoonoticStatus,
                      pred.zoostat = pred)

# # Could cut it off at the lowest true positive (min pred when zoostat = 1)
# threshold1 <- 
# filter(pred.df, true.zoostat == 1) %>%
#   summarise(min(pred.zoostat)) %>% as.numeric()
# 
# # Set cutoff threshold1
# pred.class1 <- ifelse(pred >= threshold1, 1, 0) %>% as.factor()
# 
# # Create the confusion matrix
# confusionMatrix(pred.class1, real.class, positive="1")

# Get AUC
roc.test <- pROC::roc(response = pred.df$true.zoostat, predictor = pred.df$pred.zoostat)
pROC::auc(roc.test)

# Choose threshold that maximizes G-means
threshold2 <- roc.test$thresholds[which.max(sqrt(roc.test$sensitivities*roc.test$specificities))]

# Set cutoff threshold2
pred.class2 <- ifelse(pred >= threshold2, 1, 0) %>% as.factor()

# Create the confusion matrix
confusionMatrix(pred.class2, real.class, positive="1")

# # Set cutoff threshold3
# threshold3 <- 13/228
# pred.class3 <- ifelse(pred >= threshold3, 1, 0) %>% as.factor()
# 
# # Create the confusion matrix
# confusionMatrix(pred.class3, real.class, positive="1")

```

## Deviance curves

Plot logloss curve showing how mean train and test logloss varies with the number of trees

```{r logloss_dev_plot}
# plot of logloss vs number of trees
ggplot(cv_bst_prot$evaluation_log) +
  geom_line(aes(iter, train_logloss_mean, color = "turquoise")) +
  geom_line(aes(iter, test_logloss_mean, color = "orange")) +
  scale_color_discrete(name = "Key", labels = c("Test logloss mean", "Train logloss mean")) +
  ylab("logloss (mean)") + xlab("number of trees")

# plot of AUC vs number of trees
ggplot(cv_bst_prot$evaluation_log) +
  geom_line(aes(iter, train_auc_mean, color = "turquoise")) +
  geom_line(aes(iter, test_auc_mean, color = "orange")) +
  scale_color_discrete(name = "Key", labels = c("Test AUC mean", "Train AUC mean")) +
  ylab("AUC (mean)") + xlab("number of trees")

```


```{r logloss_iter}
# get min number of trees that minimize train and test logloss
cv_bst_prot$evaluation_log %>%
  dplyr::summarise(
    ntrees.train = min(which(train_logloss_mean == min(train_logloss_mean))),
    logloss.train   = min(train_logloss_mean),
    ntrees.test  = min(which(test_logloss_mean == min(test_logloss_mean))),
    logloss.test   = min(test_logloss_mean)
  )

# get min number of trees that maximize train and test auc
cv_bst_prot$evaluation_log %>%
  dplyr::summarise(
    ntrees.train = min(which(train_auc_mean == max(train_auc_mean))),
    auc.train   = min(train_auc_mean),
    ntrees.test  = min(which(test_auc_mean == max(test_auc_mean))),
    auc.test   = max(test_auc_mean)
  )


```

Plot deviance curve showing how mean train and test errors vary with the number of trees

```{r error_dev_plot}

# Plot error vs number of trees
ggplot(cv_bst_prot$evaluation_log) +
  geom_line(aes(iter, train_error_mean, color = "turquoise")) +
  geom_line(aes(iter, test_error_mean, color = "orange")) +
  scale_color_discrete(name = "Key", labels = c("Test error mean", "Train error mean")) +
  ylab("Error (mean)") + xlab("number of trees")

```


```{r error_iter}
# get max number of trees that minimize train and test error
cv_bst_prot$evaluation_log %>%
  dplyr::summarise(
    ntrees.train = min(which(train_error_mean == min(train_error_mean))),
    error.train   = min(train_error_mean),
    ntrees.test  = min(which(test_error_mean == min(test_error_mean))),
    error.test   = min(test_error_mean)
  )

```

Can stick with the same number of trees (nrounds = 512)

# Model fitting

I built the model using the optimal parameter values identified above. I recorded the error, logloss, and AUC.

```{r fit_model}


BRT_prot <- xgboost(dtrain,
                    params = list(max.depth = 3, eta = 0.02, 
                                  nthread = 4, gamma = 0.4, alpha = 0.45,
                                  objective = "binary:logistic",
                                  eval_metric = "logloss",
                                  eval_metric = "error",
                                  eval_metric = "auc"),
                    verbose = F,
                    nrounds = 64)

BRT_prot[["evaluation_log"]] %>% tail()

ggplot(BRT_prot$evaluation_log) +
  geom_line(aes(iter, train_logloss)) +
  ylab("train logloss") + xlab("iter")

ggplot(BRT_prot$evaluation_log) +
  geom_line(aes(iter, train_error)) +
  ylab("train error") + xlab("iter")

ggplot(BRT_prot$evaluation_log) +
  geom_line(aes(iter, train_auc)) +
  ylab("train auc") + xlab("iter")

pred <- predict(BRT_prot, dtrain)

pred.df <- data.frame(true.zoostat = tmp_prot_Train$ZoonoticStatus,
                      pred.zoostat = pred)

# Choose threshold at which gives the largest G-mean score - sqrt(TPR*TNR)
roc.test <- pROC::roc(response = pred.df$true.zoostat, predictor = pred.df$pred.zoostat)
threshold <- roc.test$thresholds[which.max(sqrt(roc.test$sensitivities*roc.test$specificities))]

plot(x=roc.test$thresholds, y= sqrt(roc.test$sensitivities*roc.test$specificities), type = "b")

# generate binary predicitons
pred.class <- ifelse(pred >= threshold, 1, 0) %>% as.factor()

# Create the confusion matrix
confusionMatrix(pred.class, real.class, positive="1")

#AUC
trainAUC <- pROC::auc(roc.test)

#change na.action back to default
options(na.action=previous_na_action$na.action)
```



# Results

## Variable importance

```{r vip, echo=F, comment=F, warning = F}

importance_prot <- xgb.importance(feature_names = colnames(sparse_matrix_prot), model = BRT_prot)


ggprot1 <- xgb.plot.importance(importance_prot, rel_to_first = TRUE,
                               xlab = "Relative importance")
# # Old
# gg_prot <- xgb.ggplot.importance(importance_prot, measure = "Gain", rel_to_first = TRUE)
# gg_prot

# Create a list of the variable groups with their names
group.list <- list("generalism" = generalism, "community" = community, "hosts" = hosts,
                   "intrinsic"= intrinsic, "regional" = regional, "sampling" = sampling)

feature_grps <- unlist(group.list) %>% as.data.frame() %>% rownames_to_column()
colnames(feature_grps) <- c("Group", "Feature")
feature_grps$Group <- gsub('[[:digit:]]+', '', feature_grps$Group)

importance_prot_grp <- inner_join(ggprot1, feature_grps)
importance_prot_grp$Feature <- factor(importance_prot_grp$Feature, 
                                      levels = rev(importance_prot_grp$Feature))

ggplot(importance_prot_grp, aes(x = Feature, y = Importance)) +
  geom_bar(stat = "identity", aes(fill = Group), 
           show.legend = T) +
  coord_flip() + 
  ylab("Relative importance") + 
  scale_y_continuous(expand = c(0, 0)) + 
  scale_fill_discrete(guide = guide_legend(reverse = T))

```

Species specificity of protozoa has the highest relative importance by far. This is a bipartite network property. The R documentation description of the index: 
"Coefficient of variation of interactions, normalised to values between 0 and 1, following the idea of Julliard et al. (2006), as proposed by Poisot et al. (2012). Values of 0 indicate low, those of 1 a high variability (and hence suggesting low and high specificity). Since not corrected for number of observations, this index will yield high specificity for singletons, even though there is no information to support this conclusion."


## Partial dependence plots

Plotted for the eight most important features.

```{r pdps, echo=F, warning=F, message=F}
## partial dependence plots
important_vars <- importance_prot$Feature

v <- importance_prot$Feature
length(v)

# c-ICE curves and PDPs

p1 <- pdp::partial(BRT_prot, pred.var = as.character(important_vars[1]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2", 
              train = sparse_matrix_prot, type = "classification", prob = T)
p2 <- pdp::partial(BRT_prot, pred.var = as.character(important_vars[2]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2",
              train = sparse_matrix_prot, type = "classification", prob = T)

p3 <- pdp::partial(BRT_prot, pred.var = as.character(important_vars[3]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2", 
              train = sparse_matrix_prot, type = "classification", prob = T)
p4 <- pdp::partial(BRT_prot, pred.var = as.character(important_vars[4]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2",
              train = sparse_matrix_prot, type = "classification", prob = T)
p5 <- pdp::partial(BRT_prot, pred.var = as.character(important_vars[5]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2",
              train = sparse_matrix_prot, type = "classification", prob = T)

p6 <- pdp::partial(BRT_prot, pred.var = as.character(important_vars[6]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2", 
              train = sparse_matrix_prot, type = "classification", prob = T)

p7 <- pdp::partial(BRT_prot, pred.var = as.character(important_vars[7]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2", 
              train = sparse_matrix_prot, type = "classification", prob = T)

p8 <- pdp::partial(BRT_prot, pred.var = as.character(important_vars[8]), ice = TRUE, center = F, 
              plot = TRUE, rug = TRUE, alpha = 0.1, plot.engine = "ggplot2", 
              train = sparse_matrix_prot, type = "classification", prob = T)


grid.arrange(p1, p2, p3, ncol = 3)
grid.arrange(p4, p5, p6, ncol = 3)
grid.arrange(p7, p8, ncol = 2)

```

Interesting that parasite specificity and host specificity trend in opposite directions.

The main_biome variable is actually a factor with 16 levels (see below), so I'll have to go back and fix that. 

1. Tropical & Subtropical Moist Broadleaf Forests 
2. Tropical & Subtropical Dry Broadleaf Forests 
3. Tropical & Subtropical Coniferous Forests 
4. Temperate Broadleaf & Mixed Forests 
5. Temperate Conifer Forests 
6. Boreal Forests/Taiga 
7. Tropical & Subtropical Grasslands Savannas & Shrublands 
8. Temperate Grasslands Savannas & Shrublands 
9. Flooded Grasslands & Savannas 
10. Montane Grasslands & Shrublands 
11. Tundra 
12. Mediterranean Forests Woodlands & Scrub 
13. Deserts & Xeric Shrublands 
14. Mangroves

98. Lake 
99. Rock & Ice

# Permuting features by group


```{r permutations, eval = F}
#create a function that does the permutation for each group

# in order for model matrix to work properly, need to set na.action to pass
previous_na_action <- options('na.action')
options(na.action='na.pass')

permute_func <- function(group_vars, niter, start.seed){
  #function to do permutation to look at group variable importance
  #' @param group_vars vector of variable/column names in the group, ex. c("var1", "var2")
  #' @param niter number of iterations to do
  #' @param start.seed random seed to start with
  #' 
  #' @return AUC for each round of permutation in a vector
  
  perm_auc <- list()
  for(i in 1:niter){
    #set the seed for random permutation
    set.seed(start.seed+i)
    
    #create one permuted dataset
    perm_df <- tmp_prot_Train %>%
      mutate_at(.vars = group_vars, function(x) x[sample(nrow(tmp_prot_Train), replace = F)])
    #turn into sparseMatrix
    perm_sparse_matrix_prot <- Matrix::sparse.model.matrix(ZoonoticStatus ~ ., data = perm_df)[,-1]  
    dtrain <- xgb.DMatrix(data = perm_sparse_matrix_prot, label = tmp_prot_Train$ZoonoticStatus)
    
    pred <- predict(BRT_prot, dtrain)
    
    pred.df <- data.frame(true.zoostat = tmp_prot_Train$ZoonoticStatus,
                          pred.zoostat = pred)
    
    # Create ROC object
    roc.test <- pROC::roc(response = pred.df$true.zoostat, predictor = pred)
    
    #AUC
    perm_auc[[i]] <- pROC::auc(roc.test)
  }
  
  #turn into a vector & return
  return(do.call(c, perm_auc))
}

# Get AUCs for each round of permutation

# First create a list of the variable groups with their names
group.list <- list("generalism" = generalism, "community" = community, "hosts" = hosts,
                   "intrinsic"= intrinsic, "environmental" = regional, "sampling" = sampling)
group.list2 <- c("generalism" = generalism, "community" = community, "hosts" = hosts,
                   "intrinsic"= intrinsic, "environmental" = regional, "sampling" = sampling)

# # test on one group along
# test_perm <- permute_func(group_vars = intrinsic, niter = 10, start.seed = 500)

# Apply the permute_func over each variable group
perm.list <- lapply(group.list, permute_func, niter = 128, start.seed = 500)
skrrrahh("biggie") # play notification sound to alert when permutations are done

#turn the list into a dataframe and turn it long so it works well with dplyr and ggplot
perm.df <- bind_rows(perm.list) %>%
  mutate(perm_id = 1:n()) %>%
  pivot_longer(cols = generalism:sampling, names_to = "var_group", values_to = "AUC")

#look at summary statistics and plot
#pretend this is the full model AUC
full.AUC = trainAUC
#plot
relative.imp.grp <- 
perm.df %>%
  group_by(var_group) %>%
  summarise(med_AUC = median(AUC),
            sd_AUC = sd(AUC)) %>%
  mutate(delta_AUC = full.AUC - med_AUC) %>% 
  arrange(desc(delta_AUC))

relative.imp.grp$var_group <- factor(relative.imp.grp$var_group, levels = relative.imp.grp$var_group)

relative.imp.grp %>%
mutate(var_group = fct_reorder(var_group, delta_AUC, .desc = F)) %>%
ggplot(aes(y = var_group, x = med_AUC)) +
geom_point(aes(color = var_group), stat = "identity") +
geom_errorbarh(aes(color = var_group, xmin = med_AUC-sd_AUC, xmax = med_AUC+sd_AUC), 
               alpha = 0.8, width = 0, height = 0)



relative.imp.grp %>%
mutate(var_group = fct_reorder(var_group, delta_AUC, .desc = F)) %>%
ggplot(aes(y = var_group, x = delta_AUC)) +
geom_point(aes(color = var_group), size = 2) +
geom_errorbarh(aes(color = var_group, xmin = delta_AUC-sd_AUC, xmax = delta_AUC+sd_AUC), 
               alpha = 1, height = 0) + 
  guides(colour = guide_legend(reverse=T, title = "Variable Group")) + 
  xlab("delta AUC") + 
  ylab("Variable Group") 


```

```{r ranked predictions}


# Adapted from Ania's helminth code

pred <- predict(BRT_prot, dtrain)

pred.df <- data.frame(true.zoostat = tmp_prot_Train$ZoonoticStatus,
                      pred.zoostat = pred)

df1 <- cbind(pred.df, trainIndex_prot) %>% rename(trainIndex = Resample1)
df2 <- protnames %>% rownames_to_column() %>% rename(trainIndex = rowname) 

df2$trainIndex <- as.integer(df2$trainIndex)

df3 <- df2 %>% left_join(df1, by = "trainIndex") %>% select(-trainIndex) %>% na.omit()

df3$true.zoostat <- factor(df3$true.zoostat, labels = c("not known to be zoonotic", "known to be zoonotic"))

df4 <- df3 %>% arrange(desc(pred.zoostat))

ggplot(data=df4, aes(x=reorder(parname, -pred.zoostat), y=pred.zoostat, 
                     color = true.zoostat, fill = true.zoostat, label = parname)) +
  geom_bar(position="dodge",stat="identity") +
  labs(x = "Predicted probabilty rank", y = "Model predicted probability of being zoonotic") +
  theme_classic() +
  theme(axis.text=element_text(size=15),
        axis.title.x = element_text(size=15),
        axis.title.y = element_text(size=15),
        legend.title = element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y = element_text(size=15), legend.position = c(0.80,0.94)) +
  scale_fill_manual(values = c("#009B9F","#C75DAA")) +
  scale_color_manual(values = c("#009B9F","#C75DAA")) + 
  scale_y_continuous(expand = c(0, 0))# +
  # annotate("text", x =15.75, y = 0.98, label = "Hepatocystic kochi") +
  # annotate("text", x =17.5, y = 0.945, label = "Neospora caninum")

gmpd_zooscored <- read.csv("data/modified/gmpd_zooscored.csv")

df5 <- gmpd_zooscored %>% filter(partype == "Protozoa") %>% 
  select(parname = parname, zscore) %>% 
  left_join(df4) %>% distinct(parname, .keep_all = T) %>% 
  na.omit()

df5$zscore <- as.factor(df5$zscore)

ggplot(data=df5, aes(x=reorder(parname, -pred.zoostat), y=pred.zoostat, 
                     color = zscore, fill = zscore, label = parname)) +
  geom_bar(position="dodge",stat="identity") +
  labs(x = "Predicted probabilty rank", y = "Model predicted probability of being zoonotic") +
  theme_classic() +
  theme(axis.text=element_text(size=15),
        axis.title.x = element_text(size=15),
        axis.title.y = element_text(size=15),
        legend.title = element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y = element_text(size=15)) +
  scale_fill_manual(values = c("#009B9F","#7DC5C7", "#E4C1D8", "#D691C1", "#C75DAA"))+
  scale_color_manual(values = c("#009B9F","#7DC5C7", "#E4C1D8", "#D691C1", "#C75DAA")) + 
  scale_y_continuous(expand = c(0, 0))


```

## Test model

Same shit I guess but with tmp_prot instead of tmp_prot_Train

```{r}

# make a dtest with all the rows

# run xgboost with the fitted model

# make the plots again. you can just copy all the code and change the model name from BRT_prot to whatever the new thing is


```